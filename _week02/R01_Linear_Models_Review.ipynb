{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d3ed23",
   "metadata": {},
   "source": [
    "# DATA SCIENCE SCHOOL :: Introduction to ML in Python\n",
    "### An Intensive Python ML Course\n",
    "## Linear Models Review\n",
    "\n",
    "[&larr; Back to course webpage](http://datakolektiv.com/app_direct/introdsnontech/)\n",
    "\n",
    "![](../img/IntroMLPython_Head.png)\n",
    "\n",
    "Feedback should be send to [goran.milovanovic@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com). \n",
    "\n",
    "These notebooks accompany the DATA SCIENCE SCHOOL :: Introduction to ML in Python course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93290435",
   "metadata": {},
   "source": [
    "### Goran S. Milovanović, PhD\n",
    "<b>DataKolektiv, Chief Scientist & Owner</b>\n",
    "\n",
    "### Aleksandar Cvetković, PhD\n",
    "<b>DataKolektiv, Consultant</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad82aa2b",
   "metadata": {},
   "source": [
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28362c59",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Linear model has the form\n",
    "\n",
    "$$\\hat{y} = kx + n,$$\n",
    "\n",
    "where\n",
    "- $\\hat{y}$ - the predicted value\n",
    "- $k$ - the slope of the model\n",
    "- $n$ - the intercept of the model\n",
    "\n",
    "The error of the model $\\epsilon = y - \\hat{y}$ is normally distributed, and we find the optimal values of $n$ (intercept) and $k$ (slope) by minimizing the $SSE$. The intercept is the predicted value of $y$ when $x=0$ (i.e. where the regression line intersects the vertical, y-axis), while the slope tells us what increment in $y$ follows a unit increment in $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235f3f3",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "TThe formula for the Multiple Linear Regression Model has the form\n",
    "\n",
    "$$\\hat{y} = \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k + n,$$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\hat{y}$ - the predicted value\n",
    "- $x_1, x_2, \\ldots, x_k$ - the predictors' values\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_k$ - model's parameters for the predictors\n",
    "- $n$ - the intercept of the model\n",
    "\n",
    "The error of the model $\\epsilon = y - \\hat{y}$ is normally distributed, and we find the optimal values of $\\beta_0$ (constant) and $\\beta_i$ for $i=1,2,..k$ (coefficients) by minimizing the $SSE$. The model coefficient $\\beta_i$ tells us what increment in $y$ follows a unit increment in $x_i$ given that the values of all other predictors is kept constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5937d26",
   "metadata": {},
   "source": [
    "## Binomial Logistic Regression\n",
    "\n",
    "We use Binomial Logistic Regression to predict the probability $p$ of a given observation $\\textbf{x}$, with features $(x_1, x_2, \\ldots, x_k)$, belonging to one of the two binary categories \\{0, 1\\}. We compute these probabilites via\n",
    "\n",
    "$$p = \\frac{1}{1+e^{\\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k + n}},$$\n",
    "\n",
    "where $\\beta_1, \\beta_2, \\ldots, \\beta_k$ are the model's parameters for the predictors, and $n$ is the intercept of the model.\n",
    "\n",
    "In order to determine whether the predicted label $\\hat{y}$ for a given observation $\\textbf{x}$ has binary label 1 or 0, we impose a decision criterion $\\sigma$ - a number in the (0, 1) interval. If $p > \\sigma$, then we assign label $\\hat{y} = 1$ to the observation $\\textbf{x}$; else, we take $\\hat{y} = 0$. Ususally, we take $\\sigma = 0.5$.\n",
    "\n",
    "The model is optimized by MLE (Maximum Likelihood Estimation), and the interpretation of the model coefficients is the following:\n",
    "\n",
    "- for a given predictor $x_i$, the exponential of its coefficient, $e^{\\beta_i}$ tells us about the change $\\Delta_{odds}$, where $\\Delta_{odds}$ is the difference between $\\frac{p_1}{1-p_1}$ *following* a unit increase in $x_i$ and before it - given that everything else is kept constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f1ce2",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression\n",
    "\n",
    "We use Multinomial Logistic Regression Model to predict the most probable category for the given observation $\\textbf{x}$ with features $(x_1, x_2, \\ldots, x_k)$. Assume that our target variable $y$ belongs to one of categories from the set $\\{1, 2, \\ldots, C\\}$. In MLR we usually select one category as the referrence category; let that be the category $C$. Then, the probability that the target variable $y$ belongs to category $c = 1,\\ldots,C-1$ is calculated via\n",
    "\n",
    "$$P(y = c) = \\frac{e^{\\beta^{(c)}_1x_1 + \\beta^{(c)}_2x_2 + \\cdots + \\beta^{(c)}_kx_k + n}}{1+\\sum_{j=1}^{C-1}e^{\\beta^{(j)}_1x_1 + \\beta^{(j)}_2x_2 + \\cdots + \\beta^{(j)}_kx_k + n}},$$\n",
    "\n",
    "and the probability that it belogns to the referrence category $C$ is \n",
    "\n",
    "$$P(y = C) = \\frac{1}{1+\\sum_{j=1}^{C-1}e^{\\beta^{(j)}_1x_1 + \\beta^{(j)}_2x_2 + \\cdots + \\beta^{(j)}_kx_k + n}},$$\n",
    "\n",
    "where $\\beta^{(j)}_1, \\beta^{(j)}_2, \\ldots, \\beta^{(j)}_k,\\ j=1,\\ldots,C$ are the model's parameters for predictors and target variable categories, and $n$ is the intercept of the model.\n",
    "\n",
    "After calculating all the probabilities $P(y = c),\\ c=1,\\ldots,C$ we predict the target variable as\n",
    "\n",
    "$$\\hat{y} = \\textrm{argmax}_{c=1,\\ldots,C}P(y=c).$$\n",
    "\n",
    "The model is estimated by MLE (Maximum Likelihood Estimation). For each category $c$ - except for the referrence $C$, of course - we obtain a set of coefficients. Each model coefficient, in each category, tells us about the $\\Delta_{odds}$ in favor of the target category, for a unit change of a predictor, in comparison with the baseline category, and given that everything else is kept constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c70c8",
   "metadata": {},
   "source": [
    "Goran S. Milovanović & Aleksandar Cvetković\n",
    "\n",
    "DataKolektiv, 2022/23.\n",
    "\n",
    "[hello@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com)\n",
    "\n",
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1e343",
   "metadata": {},
   "source": [
    "<font size=1>License: <a href=\"https://www.gnu.org/licenses/gpl-3.0.txt\">GPLv3</a> This Notebook is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This Notebook is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this Notebook. If not, see <a href=\"http://www.gnu.org/licenses/\">http://www.gnu.org/licenses/</a>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9e496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
